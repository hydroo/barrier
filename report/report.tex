\documentclass[a4paper, 10pt]{article}

\usepackage{cite}
\usepackage{color}
	\definecolor{gray}{rgb}{0.5,0.5,0.5}
\usepackage{datetime}
\usepackage{fancyvrb}
\usepackage{graphicx}
\graphicspath{{images/}}
\DeclareGraphicsExtensions{.pdf,.png}
%\usepackage{hyperref}
\usepackage{latexsym}
\usepackage{listings}
	\lstset{
		frame=single,
		numbers=left,
		numberstyle=\small\color{gray},
		tabsize=4,
		morekeywords={and, boolean, do, else, false, for, if, integer, mod, true, until, wait, while},
	}
\usepackage{multirow}
\usepackage{setspace}
\usepackage{url}

\def \todo{\textbf{\textcolor{yellow}{TODO}}}
\def \citationneeded{\textbf{\textcolor{yellow}{CITATION NEEDED}}}

\title{Development and Analysis of Barrier Protocols}
\author{Ronny Brendel\\Tutors: Sascha Kl\"uppelholz \& Marcus V\"olp}

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagenumbering{gobble}

\begin{titlepage}

\begin{center}
\includegraphics[width=3cm]{tu-logo}~\\[1cm]
\textsc{\LARGE Dresden University of Technology}\\[0.5cm]
\textsc{\Large Faculty of Computer Science}\\[0.2cm]
\textsc{\large Institute of Theoretical Computer Science}\\[0.2cm]
\textsc{\large Chair for Algebraic and Logical Foundations of Computer Science}\\[3cm]
\Huge Study's Thesis \\[1cm]
\huge Development and Analysis of Barrier Protocols\\[3cm]
\end{center}

\begin{flushleft} \large
	Author: Ronny Brendel \\
	Responsible university professor: Christel Baier \\
	Supervisors: Sascha Kl\"uppelholz \& Marcus V\"olp
\end{flushleft}

\vfill
\begin{flushright}
	\large October 2013
\end{flushright}

\end{titlepage}

\pagebreak
\newpage \thispagestyle{empty} \mbox{}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Aufgabenstellung}

\pagebreak
\newpage \thispagestyle{empty} \mbox{}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section*{Selbstst\"andigkeitserkl\"arung}
%Ich erkl\"are hiermit, dass ich die vorliegende Arbeit selbst\"andig und ohne Benutzung anderer als der angegebenen Hilfsmittel angefertigt habe. Die aus fremden Quellen w\"ortlich oder sinngem\"a\ss ~\"ubernommenen Gedanken sind als solche kenntlich gemacht. Ich erkl\"are ferner, dass ich die vorliegende Arbeit an keiner anderen Stelle als Pr\"ufungsarbeit eingereicht habe oder einreichen werde.

\section*{Statement of academic integrity}
I hereby declare that I prepared this thesis independently and without use of tools other than specified. Foreign thoughts, taken literally or in spirit, are marked as such. I also declare that I have not filed the present work at any other location or will submit it.

\pagebreak
\newpage \thispagestyle{empty} \mbox{}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\renewcommand{\contentsname}{Table of contents}
\tableofcontents

\pagebreak
\newpage \thispagestyle{empty} \mbox{}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagenumbering{arabic}
\section{Don't forget}
\begin{itemize}
	\item try all algorithms with processor counts $\neq 2^i$ especially dissemination
	\item explain use of 'thread' and 'process'
	\item explain constants used in listings somewhere
		\begin{itemize}
			\item threadCount/processCount
			\item threadIndex/processIndex
			\item ?more?
		\end{itemize}
\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\begin{itemize}
	\item general introduction
	\item what is a barrier
	\item usage example for barriers. Reference rab00.
	\item motivation for researching barrier
	\item ?historical development?
	\item ?overarching thesis that will be worked on. Add a claim as recurrent theme.?
	\item what this report will be about
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Survey of means to implement barrier protocols}
\begin{itemize}
	\item evaluate what tools we have at our disposal to realize barrier protocols
	\item the influence of communication latency
	\item bandwidth doesn't matter, because data transfered is small.
	\item shared vs distributed memory - explain both
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Shared memory}
\begin{itemize}
	\item atomic ops. most notably add-fetch, compare-swap \citationneeded
	\item normal load/store
	\item weaken memory model. default on x86 is sequential consistency. explain. \citationneeded. Most prominent weaker memory consistency model is release consistency \cite{gha90}.
		One must pay attention when implementing, but gains performance.
	\item hardware support e.g. SGI UV 2000 systems\cite{sgiuv2000}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Distributed memory}
\begin{itemize}
	\item categories
		\begin{itemize}
			\item synchronous message passing
				\begin{itemize}
					\item relatively large overhead. Queueing. Waiting even when sending.
					\item all communicating partners need to be present at the same time and shake hands.
				\end{itemize}
			\item asynchronous message passing
				\begin{itemize}
					\item similar overhead as synchronous message passing. not necessarily waiting.
					\item but partners still need to shake hands for information transfer.
				\end{itemize}
			\item RMA
				\begin{itemize}
					\item explain short what RMA is\citationneeded. Coop between RAM and network card needed.
					\item needs hardware support.
					\item less software overhead, since it is one sided. Less buffering. Ideally no buffering.
					\item (a) coherent - remotely updated memory will be visible to the remote end eventually
					\item (b) non-coherent - no guarantee about visibility of remotely updated memory - needs active asking for changes by the remote end.
				\end{itemize}
			\item hardware support here is usual business e.g. Earth Simulator\cite{earthsimulator}, IBM Blue Gene/L\cite{bluegenel}, IBM Blue Gene/Q\cite{bluegeneq}, low-cost custom\cite{hoefler2006b}
			\item lossy communication e.g.
				\begin{itemize}
					\item most of today's synchronization protocols are based on a reliable communication layer e.g. TCP, InfiniBand's reliable connections. Many support unreliable connections though, e.g. UDP~\cite{udp}, infiniband's unreliable connections~\cite{infiniband}.
					\item it is easy to imagine algorithms for lossy channels. Gain performance through less checks, e.g. message receive acknowledges. Add algorithms that tolerate this behaviour and there you go.
				\end{itemize}
		\end{itemize}
	\label{why-only-mpi}
	\item we specifically look at MPI. Explain short why only MPI.
		\begin{itemize}
			\item low-level
			\item standardized
			\item portable, dist and shared mem, MPP, clusters of workstations, and combinations, independent on particular platform features or quantitative differences
			\item many implementations of the standard for many programming languages exist
			\item very general and customizable. Supports many modes of operation.
			\item widely adopted in cluster computing / HPC, scientific computing.~\cite{mpiadoptiona}\cite{mpiadoptionb}\cite{mpiadoptionc}
		\end{itemize}
	\item only scratch surface of MPI 3.0, because:
		\begin{itemize}
			\item a lot of details, because of generality, optimizability
			\item complicated semantics
			\item many of the details make no striking difference in protocol design/analysis
		\end{itemize}
	\item MPI has synchronous message passing
		\begin{itemize}
			\item chapter 3.2 in \cite{mpi3}
			\item MPI\_Ssend, MPI\_Rsend (returns if no receiver is present), MPI\_Recv
		\end{itemize}
	\item MPI has asynchronous message passing
		\begin{itemize}
			\item chapter 3.7 in \cite{mpi3}
			\item MPI\_Isend, MPI\_Irecv
			\item MPI\_Wait, MPI\_Test
			\item MPI\_Cancel
			\item sync and async message passing can be mixed e.g. MPI\_Isend with a matching MPI\_Recv
		\end{itemize}
	\item MPI has asynchronous collectives
		\begin{itemize}
			\item chapter 5.12 in \cite{mpi3}
			\item non-blocking collectives are not interesting as a building block for new barriers, because everyone has to take part and no cancellation of anything is possible.
		\end{itemize}
	\item MPI has RMA
		\begin{itemize}
			\item chapter 11 in \cite{mpi3}
			\item major changes from MPI 2.2 to 3.0\cite{mpi3onesided}
			\item we will only consider MPI 3.0, because: More features. Subsumes MPI 2.2. It is already one year old. It is not yet realized by openmpi, but it is for mpich 3.0 and derivatives such as MVAPICH2\citationneeded, Cray MPT\cite{craympt}
			\item following we will only consider MPI 3.0
				\begin{itemize}
					\item MPI\_Win\_Create creates a so called 'window' of remotely shared memory among the participating process. A process group is associated with a window.
					\item customizable attributes of windows: give the implementation guarantees about not using certain operations, not using certain operations at the same time, lowering memory consistency requirements for certain operations(accumulate).
					\item MPI\_WIN\_MODEL: explain SEPARATE and UNIFIED. One cannot set the MPI\_WIN\_MODEL to MPI\_WIN\_SEPARATE and MPI\_WIN\_UNIFIED myself. You can only ask for it. It has been proposed for MPI 3.1 to include being able to set a minimum necessary level. Algorithms for separate work on unified as well, but not necessarily the other way round.
					\item mpich 3.0.4 does MPI\_WIN\_UNIFIED.
					\item explaining epochs:
						\begin{itemize}
							\item an epoch is a period between two window synchronization calls
							\item rma calls data transfer calls like put, get, accumulate can only be used inside an epoch
							\item used to accumulate multiple calls etc -$\>$ efficiency
							\item MPI distinguishes access and exposure epochs, but we will ignore these.
						\end{itemize}
					\item window sync
						\begin{itemize}
							\item active vs passive target communication (\cite{mpi3} page 437~)
							\item MPI\_Win\_Fence. Active target communication. Is a collective over all window group members. All outstanding RMA requests between group members will be finished implies a barrier.
							\item MPI\_Win\_Start, MPI\_Win\_Complete, MPI\_Win\_Post, and MPI\_Win\_Wait: active target communication. Similar to fence, but allows to specify the sync partners exactly, and distinguishes between "command-issuing" and "remotely-accessed" processes.
							\item MPI\_WIN\_LOCK, MPI\_WIN\_UNLOCK: Passive target communication. No explicit participation of remote end in synchronization
							\item MPI\_Flush*: Passive target communication. Completes outstanding RMA calls, issued by the caller, at origin and a specifiable target before returning (or only at the origin).
							\item MPI\_Sync: Passive target communication. Used to synchronize the public and private part of the window in the separated model.
						\end{itemize}
					\item window sync assertions: NoPrecede, NoSucceed, NoStore, NoPut -$\>$ optimization
					\item MPI\_Put, MPI\_Get - unordered inside an epoch
					\item MPI\_Accumulate, MPI\_FetchAndOp, MPI\_CompareAndSwap influenced by specified memory order requirements. default is sequential consistency.
					\item list cases of undefined(implementation specific) behaviour: chapter 11.3 and 11.7 in \cite{mpi3}
						\begin{itemize}
							\item Buffers used in a MPI\_Put call should not be written to until the operation completes
							\item Buffers used in a MPI\_Get call should not be accessed until the operation completes
							\item The outcome of remote memory accesses to the same location is undefined. Except of course accumulate.
							\item concurrent local load/stores and RMA updates to the same location are undefined
							\item the outcome of a single process issuing multiple puts to the same location within an access epoch is undefined
							\item State this makes it harder to implement less restrictive synchronization primitives because the semantic requirements are already very strong in MPI. Lots of perhaps useless synchronization. Rather than undefined say: any order. Or at least make guarantee for the smallest units that are atomically committed to memory like primitive data types.
						\end{itemize}
				\end{itemize}
		\end{itemize}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Survey of currently used barriers}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Shared memory systems}
\begin{itemize}
	\item explain short why only research in glibc and gnu openmp. closed source intel, microsoft, portland pgi, pathscale. pthreads und openmp open source und weit verbreitet. ?llvm?
	\item gnu openmp
		\begin{itemize}
			\item gcc 4.8.0, linux
			% gnu-openmp/gcc-4.8.0/libgomp/libgomp.h
			% gnu-openmp/gcc-4.8.0/libgomp/barrier.c
			% gnu-openmp/gcc-4.8.0/libgomp/config/linux/
			% gnu-openmp/gcc-4.8.0/libgomp/config/linux/bar.h
			% gnu-openmp/gcc-4.8.0/libgomp/config/linux/bar.c
			% gnu-openmp/gcc-4.8.0/libgomp/config/linux/futex.h (cpu_relax)
			% gnu-openmp/gcc-4.8.0/libgomp/config/linux/wait.h
			\item central counter barrier with atomic add and fetch
			\item listing~\ref{listing:central-counter-no-reset}
				\begin{figure}[htbp]
					\centering
					\input{listings/central-counter-no-reset}
					\caption{Pseudo code of the central counter barrier}
					\label{listing:central-counter-no-reset}
				\end{figure}

			\item back-off via a spin-counter $\sim$ 3ms. architecture specific. lowers spincount if cpucount $<$ threadcount. futexes\cite{franke2002}. kernel based mutexes. wait queues. sleeping.
			\item reset built in. last one to enter resets the barrier.
		\end{itemize}
	\item glibc's new pthreads library
		\begin{itemize}
			\item version 2.17. is in my ubuntu raring 13.04.
			% glibc/nptl/sysdeps/pthread/pthread.h
			% glibc/nptl/pthread_barrier_*
			% glibc/nptl/sysdeps/unix/sysv/linux/internaltypes.h
			\item central counter with explicit locking instead of atomic add-fetch
			\item back-off through futexes (without spinning before)
			\item reset handled automatically (upon leaving the barrier every thread increments (atomically) the barrier by 1 so that it is max in the end)
		\end{itemize}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Distributed memory systems}
\begin{itemize}
	\item why only MPI. Already explained in section~\ref{why-only-mpi}.
	\item openmpi
		\begin{itemize}
			\item version 1.7. not yet released.
			% ompi/mca/coll/tuned/coll_tuned_barrier.c :
			% ompi_coll_tuned_barrier_intra_recursivedoubling,
			% ompi_coll_tuned_barrier_intra_bruck
			% ompi/mca/coll/tuned/coll_tuned_decision_fixed.c
			\item $n \neq 2^k \rightarrow$ dissemination\cite{hensgen1988} using sync sendrecv
			\item $n = 2^k \rightarrow$ recursive doubling (explanation e.g. in \cite{hoefler2005})
			\item back-off hard to determine. probably through OPAL\_THREAD\_(UN)LOCK in the end
			\item resetting (in both algorithms) not necessary since sendrecv sets up itself newly everytime.
			\item architecture specific for infiband. e.g. dissemination using RMA \cite{hoefler2006a}
			\item listing~\ref{listing:dissemination-no-reset}
				\begin{figure}[htbp]
					\centering
					\input{listings/dissemination-no-reset}
					\caption{Pseudo code of the dissemination barrier}
					\label{listing:dissemination-no-reset}
				\end{figure}
			\item things to explain
				\begin{itemize}
					\item each array (first index) is located on the respective process's memory
				\end{itemize}

		\end{itemize}
	\item mpich
		\begin{itemize}
			\item many mpi implementations are based on mpich (e.g. mvapich2, intel mpi, cray mpi,
			\item many can not be inspected because source is closed
			\item version 3.0.4. current today
			% src/mpi/coll/barrier.c : MPIR_Barrier_intra
			\item log2 Dissemination with sendrecv. same as openmpi
		\end{itemize}
	\item dissemination can also be used for shared memory\cite{hoefler2013}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Three new barriers}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{NMG/Ronny}
\begin{itemize}
	\item listing~\ref{listing:nmg-ronny-with-reset}
		\begin{figure}[htbp]
			\centering
			\input{listings/nmg-ronny-with-reset}
			\caption{Pseudo code of nmg/ronny's barrier}
			\label{listing:nmg-ronny-with-reset}
		\end{figure}

	\item things to explain
		\begin{itemize}
			\item ~
		\end{itemize}

	\item reference old work
	\item mention errors -$>$ correction
	\item improvement (remember others)
	\item still slow and inefficient
	\item resetting included in the protocol
	\item advantage: no atomic ops
	\item + variations: array based for more than 64 threads
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Ronny's simple barrier}
\begin{itemize}
	\item listing~\ref{listing:ronny-simple-no-reset}
		\begin{figure}[htbp]
			\centering
			\input{listings/ronny-simple-no-reset}
			\caption{Pseudo code of ronny's simple barrier}
			\label{listing:ronny-simple-no-reset}
		\end{figure}

	\item things to explain
		\begin{itemize}
			\item ~
		\end{itemize}

	\item advantage: no atomic ops
	\item much shared read communication but low computation overhead
	\item ?discuss a variant with reset?, if not at least mention that reset is not handled here
	\item + variations: remember first few, remember last few, more?
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Ronny's fancy barrier}
\begin{itemize}
	\item listing~\ref{listing:ronny-fancy-no-reset}
		\begin{figure}[htbp]
			\centering
			\input{listings/ronny-fancy-no-reset}
			\caption{Pseudo code of ronny's fancy barrier}
			\label{listing:ronny-fancy-no-reset}
		\end{figure}

	\item things to explain
		\begin{itemize}
			\item each array element is located in its own process - dist mem
		\end{itemize}

	\item advantage: no atomic ops
	\item trades computational overhead for, less shared read communication than the simple variant
	\item ?discuss a variant with reset?, if not at least mention that reset is not handled here
	\item + variations: which?
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Analysis and comparison of the contenders}

\begin{itemize}
	\item pick central counter barrier as contender for shared mem
	\item pick dissemination as contender for distributed mem
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Theoretical aspects}
\begin{itemize}
	\item mention that no back-off is used. Busy waiting. Wait spinning.
\end{itemize}

\subsubsection{Central counter vs ronny's simple barrier}
\subsubsection{Dissemination vs ronny's fancy barrier}
\begin{itemize}
	\item number of messages sent vs the minimum necessary
	\item progress problem when one process is missing
	\item meantion the xeon phi work of TH
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Benchmarks}
\begin{itemize}
	\item central counter vs ronny simple
	\item do not do dissemination vs ronny fancy
	\item ?rapl?
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Model checking}
\subsubsection{Qualitative Properties (correctness)}
\begin{itemize}
	\item threads may only exit the barrier if all threads are present
	\item the protocol must always terminate, or in other words: if all threads are present, they will all exit the barrier in a finite amount of time"
\end{itemize}
\subsubsection{Quantitative Properties}
\begin{itemize}
	\item central counter vs ronny simple
	\item dissemination vs ronny fancy
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proposal: Creating barriers from orthogonal parts}
Cut up existing barriers into orthogonal pieces. Analyse and replace them independently.
\begin{itemize}
	\item more or less intelligence / bandwidth/latency vs additional calculations
	\item 
		reset

		\begin{itemize}
			\item how is resetting handled in currently used barriers?
			\item switching between barriers using a variable (as in the nmg/ronny barrier - 'left' variable)
			\item use 3 barriers reset barrier x+2 when you finished barrier x. switch between the barriers by checking if barrier x+2 is reset or not (as in central-counter-with-reset)
			\item if variable space permits it you can also change the variables to 'counters' and modify all checks to ask for numbers modulo round + a check that you are in the proper round
		\end{itemize}

	\item back-off
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
\begin{itemize}
	\item condense results into a small passage
	\item ?repeat claim - overarching thesis - present an answer?
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future Work}
\begin{itemize}
	\item evaluate back-off strategies. mwait.
	\item model check more and bigger. symmetry reduction. partial order reduction.
	\item explore variations of ronny's barriers
		\begin{itemize}
			\item use remote write \& local read instead of local write \& remote read, because remote writing is preferred on some platforms, e.g. on the Epiphany\cite{epiphany}.
		\end{itemize}
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{Appendix}
\subsection{e.g. source code, model source}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{Glossary}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{Bibliography}
\renewcommand\refname{\vskip -1cm} %TODO fine tune perhaps
\nocite{*} % insert not cited references
\bibliographystyle{abbrv}
\bibliography{bibliography}{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{List of Figures}
\renewcommand{\listfigurename}{\vskip -1cm} %TODO fine tune perhaps
\listoffigures

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{List of Tables}
\renewcommand{\listtablename}{\vskip -1cm} %TODO fine tune perhaps
\listoftables

\end{document}
